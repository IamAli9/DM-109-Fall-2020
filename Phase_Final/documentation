
## What is Dynamic Programming ## 

Dynamic programming approach is similar to divide and conquer in breaking down the problem into smaller and yet smaller possible sub-problems. 
But unlike, divide and conquer, these sub-problems are not solved independently. Rather, results of these smaller sub-problems are remembered and used for
similar or overlapping sub-problems.
The Challenges We Faced
Dynamic programming is rather difficult when compared to other techniques. We tried building the concepts on multiple instances but the support and concepts
for Dynamic Programming are rare on the internet. Also, the support for JavaScript is yet minimal with context to dynamic programming. Tried implementing dynamic 
programming, it is convenient in a way that we don’t need to specify the data types and such instances can be decided on the runtime, initially we make the generic
objects, but due to this it takes more processing power and memory. The concept of Dynamic Programming was to introduce optimization in code and algorithms, 
but cannot be utilized yet fully. Also, the support for dynamic programming is rather less hence we faced multiple challenges while implementing it.
Conclusion
All in all, Dynamic programming is a great approach and an optimal way to write algorithms, yet the support for dynamic programming is not ideal but surely 
with time it will evolve and hopefully will get the maximum utilization out of it with online assistance.

What kinds of problems can be solved using Dynamic Programming? One property these problems
have is that if the optimal solution involves solving a subproblem, then it uses the optimal solution
to that subproblem. For instance, say we want to find the shortest path from A to B in a graph,
and say this shortest path goes through C. Then it must be using the shortest path from C to B.
Or, in the knapsack example, if the optimal solution does not use item n, then it is the optimal
solution for the problem in which item n does not exist. The other key property is that there
should be only a polynomial number of different subproblems. These two properties together allow
us to build the optimal solution to the final problem from optimal solutions to subproblems.
In the top-down view of dynamic programming, the first property above corresponds to being
able to write down a recursive procedure for the problem we want to solve. The second property
corresponds to making sure that this recursive procedure makes only a polynomial number of
different recursive calls. In particular, one can often notice this second property by examining
the arguments to the recursive procedure: e.g., if there are only two integer arguments that range
between 1 and n, then there can be at most n
2 different recursive calls.
Sometimes you need to do a little work on the problem to get the optimal-subproblem-solution
property. For instance, suppose we are trying to find paths between locations in a city, and some
intersections have no-left-turn rules (this is particulatly bad in San Francisco). Then, just because
the fastest way from A to B goes through intersection C, it doesn’t necessarily use the fastest way
to C because you might need to be coming into C in the correct direction. In fact, the right way
to model that problem as a graph is not to have one node per intersection, but rather to have one
node per hintersection, directioni pair. That way you recover the property you need.

FORMALIZING THE DYNAMIC-PROGRAMMING APPROACH
The elementary example presented in the previous section illustrates the three most important characteristics
of dynamic-programming problems:
Stages
The essential feature of the dynamic-programming approach is the structuring of optimization problems
into multiple stages, which are solved sequentially one stage at a time. Although each one-stage problem
is solved as an ordinary optimization problem, its solution helps to define the characteristics of the next
one-stage problem in the sequence.
Often, the stages represent different time periods in the problem’s planning horizon. For example, the
problem of determining the level of inventory of a single commodity can be stated as a dynamic program.
The decision variable is the amount to order at the beginning of each month; the objective is to minimize the
total ordering and inventory-carrying costs; the basic constraint requires that the demand for the product be
satisfied. If we can order only at the beginning of each month and we want an optimal ordering policy for
the coming year, we coulddecompose the problem into 12 stages, each representing the ordering decision at
the beginning of the corresponding month.
Sometimes the stages do not have time implications. For example, in the simple situation presented
in the preceding section, the problem of determining the routes of minimum delay from the homes of the
commuters to the downtown parking lots was formulated as a dynamic program. The decision variable was
whether to choose up or down in any intersection, and the stages of the process were defined to be the number
of intersections to go. Problems that can be formulated as dynamic programs with stages that do not have
time implications are often difficult to recognize.
States
Associated with each stage of the optimization problem are the states of the process. The states reflect
the information required to fully assess the consequences that the current decision has upon future actions.
In the inventory problem given in this section, each stage has only one variable describing the state: the
inventory level on hand of the single commodity. The minimum-delay problem also has one state variable:
the intersection a commuter is in at a particular stage.
The specification of the states of the system is perhaps the most critical design parameter of the dynamicprogramming model. There are no set rules for doing this. In fact, for the most part, this is an art often
requiring creativity and subtle insight about the problem being studied. The essential properties that should
motivate the selection of states are:
i) The states should convey enough information to make future decisions without regard to how the process
reached the current state; and
ii) The number of state variables should be small, since the computational effort associated with the dynamicprogramming approach is prohibitively expensive when there are more than two, or possibly three, state
variables involved in the model formulation
